<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Hard-SVM - 魔法沉思录</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="魔法沉思录"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="魔法沉思录"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="支持向量机（Support Vector Machine）， 是一种解决分类和回归的经典机器学习模型。以解决分类问题为例，它的核心思想是，最大化输入向量到超平面的间隔。"><meta property="og:type" content="blog"><meta property="og:title" content="Hard-SVM"><meta property="og:url" content="https://codeflysafe.github.io/2020/09/27/SVM(1)_%20Hard-SVM/"><meta property="og:site_name" content="魔法沉思录"><meta property="og:description" content="支持向量机（Support Vector Machine）， 是一种解决分类和回归的经典机器学习模型。以解决分类问题为例，它的核心思想是，最大化输入向量到超平面的间隔。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://images.pexels.com/photos/1714208/pexels-photo-1714208.jpeg?auto=compress&amp;cs=tinysrgb&amp;dpr=2&amp;w=500"><meta property="article:published_time" content="2020-09-27T08:14:19.000Z"><meta property="article:modified_time" content="2022-02-18T09:11:35.641Z"><meta property="article:author" content="sjhuang"><meta property="article:tag" content="machine learning"><meta property="article:tag" content="classification"><meta property="article:tag" content="SVM"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://images.pexels.com/photos/1714208/pexels-photo-1714208.jpeg?auto=compress&amp;cs=tinysrgb&amp;dpr=2&amp;w=500"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://codeflysafe.github.io/2020/09/27/SVM(1)_%20Hard-SVM/"},"headline":"Hard-SVM","image":[],"datePublished":"2020-09-27T08:14:19.000Z","dateModified":"2022-02-18T09:11:35.641Z","author":{"@type":"Person","name":"sjhuang"},"publisher":{"@type":"Organization","name":"魔法沉思录","logo":{"@type":"ImageObject","url":"https://codeflysafe.github.io/img/logo.svg"}},"description":"支持向量机（Support Vector Machine）， 是一种解决分类和回归的经典机器学习模型。以解决分类问题为例，它的核心思想是，最大化输入向量到超平面的间隔。"}</script><link rel="canonical" href="https://codeflysafe.github.io/2020/09/27/SVM(1)_%20Hard-SVM/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><!--!--><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><meta name="generator" content="Hexo 5.4.0"></head><body class="is-1-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="魔法沉思录" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a><a class="navbar-item" href="/love">Love</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-12"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="https://images.pexels.com/photos/1714208/pexels-photo-1714208.jpeg?auto=compress&amp;cs=tinysrgb&amp;dpr=2&amp;w=500" alt="Hard-SVM"></span></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-09-27T08:14:19.000Z" title="2020/9/27 下午4:14:19">2020-09-27</time>发表</span><span class="level-item"><time dateTime="2022-02-18T09:11:35.641Z" title="2022/2/18 下午5:11:35">2022-02-18</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/machine-learning/">machine learning</a></span><span class="level-item">9 分钟读完 (大约1295个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">Hard-SVM</h1><div class="content"><p>支持向量机（Support Vector Machine）， 是一种解决分类和回归的经典机器学习模型。以解决分类问题为例，它的核心思想是，最大化输入向量到超平面的间隔。</p>
<span id="more"></span>

<p>之前在 <a target="_blank" rel="noopener" href="https://www.yuque.com/hsjfans/hdu6yd/ff882d">感知机</a> 里面我们已经了解到其思想为找到一个超平面，来划分特征空间为正负空间，从而实现分类的目的（如下图）。<img src="https://s3.bmp.ovh/imgs/2022/02/234ed2712e5b0f2a.png"><br><br />但是，这样的超平面不只一个，怎么来从中找到一个最优的超平面呢？ 如何评价超平面的优劣呢？这就是SVM解决分类问题的思想。<br /></p>
<h2 id="1-Hard-SVM"><a href="#1-Hard-SVM" class="headerlink" title="1. Hard-SVM"></a>1. Hard-SVM</h2><h3 id="1-1-模型"><a href="#1-1-模型" class="headerlink" title="1.1 模型"></a>1.1 模型</h3><p><br />SVM的思想，通俗来讲是，最大化 Margin(x), Margin(x)代表为，所有点到超平面距离中的最小距， 即 $\min{Distance(x_i)}$ i = 1,2,3…,n<br />化为最优化的标准型为：<br /><br><br /></p>
<p>$$\max_{w,b}Margin(x) = \max_{w,b} \min_{x_i}Distance(x_i) \<br>= \max_{w,b}\min_{x_i} \frac{|w^Tx_i + b|}{||w||} \<br>s.t. \quad  y_i(w^Tx_i + b) &gt; 0$$</p>
<p><br />由于 y = 1 or -1， 且分类正确时 $y（w^x + b）&gt; 0$, 因此 $｜w^T + b｜ = y(w^T + b)$<br />这里假设，$y(w^Tx +b ) &gt;= \sigma &gt; 0$, 此时问题改写为：<br />$\max_{w,b} \frac{\sigma}{||w||} \<br>s.t. \quad y_i(w^Tx_i + b) &gt;= \sigma$</p>
<p>由于我们可以等比例的修改 w和b是的，$\sigma$ 变为 1， 这样做并不改变问题的解。同时，$\frac{1}{||w||}$等同于$\frac{w^Tw}{2}$，此时问题修改为：</p>

$$
\begin{aligned}
&\min_{w,b}\frac{w^Tw}{2}  \\
s.t. \quad &y_i(w^Tx_i + b) -1 >= 0 
\end{aligned} \tag{2}
$$


<p><br />由于该问题是典型的二次优化问题，可以采用优化工具包来解决，也可以转化为对偶问题解决。<br /></p>
<p><a name="lxoaX"></a></p>
<h3 id="2-策略"><a href="#2-策略" class="headerlink" title="2. 策略"></a>2. 策略</h3><p>如何求解式（1）中的二次优化问题，这里可以采用拉格朗日乘法来解决。采用拉格朗日乘法有一个前提，即该问题满足 KKT 条件<br /></p>
<p><a name="To4uv"></a></p>
<h4 id="2-1-Dual-Problem"><a href="#2-1-Dual-Problem" class="headerlink" title="2.1  Dual Problem"></a>2.1  Dual Problem</h4><p><br />优化问题的标准形式为:<br /></p>
<p>$\max_{x} f(x) \<br>s.t. \quad h(x_i) = 0 \<br>\quad g(x_i) &gt;= 0  \quad(2)\<br>$</p>
<p><br />这里引入广义拉格朗日乘法:</p>
<p>$$<br>L(x,\lambda,\eta) = f(x) - \sum_i \lambda_ih(x_i) - \sum_i\eta_ig(x_i)<br> \quad(3) \<br>\eta_i &gt;= 0<br>$$</p>
<p><br />考虑x的函数<br>$\theta_p(x) = \max_{\lambda,\eta,\eta &gt;= 0} L(x,\lambda,\eta)$<br><br />如果x不满足式（2）中的约束条件，即存在 $h(x) \neq 0$ 或者 $g(x) &lt; 0$, 此时总存在 一个$\lambda$ 或者$\eta$ 使得， <br />$\eta g(x) \rightarrow +\infty \<br>\lambda h(x) \rightarrow +\infty$<br />而当 x符合（2）中条件时，$\theta_P(x) = f(x)$。<br /><br><br />因此考虑极小化问题，</p>
<p>$$<br>\begin{aligned}<br>&amp;\min_{x}{f(x)} = \min_{x}{\theta_p(x)} = \min_{x} \max_{\lambda,\eta,\eta &gt;= 0}{L(x,\eta,\lambda)} \<br>&amp;\text{Dual Problem} \max_{\lambda, \eta; \eta &gt;= 0} \min_{x L(x,\eta,\lambda)}<br>\end{aligned}<br>$$</p>
<p>设：<br />$p^{\star} = \min_{x}\theta_p(x) \<br>d^{\star} = \max_{\lambda, \eta;\eta &gt;= 0} \min_{x} L(x,\eta,\lambda)$<br />则有：</p>
<p>$$<br>\min_{x}L(x,\eta,\lambda) &lt;= L(x,\eta,\lambda)  &lt;= \max_{\lambda,\eta,\eta &gt;= 0}{L(x,\eta,\lambda)} \<br>\rightarrow \quad d^{\star} &lt;= p^{\star}<br>$$ <br>当 优化问题的解满足 KKT条件时， $d^{\star} = p^{\star}$<br /></p>
<p><a name="gkZSn"></a></p>
<h4 id="2-2-KKT条件"><a href="#2-2-KKT条件" class="headerlink" title="2.2 KKT条件"></a>2.2 KKT条件</h4><p><br />把下面的条件记作 KKT 条件：</p>

$$
\begin{aligned}
\triangledown L(x,\lambda,\eta) = 0 \\
\eta_i >= 0 \\
\eta_ig(x_i) = 0 \\
g(x_i) >=0 \\
h(x_i) = 0
\end{aligned}
$$


<p>证明：</p>
<ol>
<li>$当g(x_i) &gt; 0 时，此时条件 g(x_i) 不起作用，为等式约束，此时 \eta_i = 0$</li>
<li>$当 g(x_i) = 0时，此时 \eta_ig(x_i) = 0$</li>
</ol>
<p><a name="QnBQv"></a></p>
<h4 id="2-3-模型求解"><a href="#2-3-模型求解" class="headerlink" title="2.3 模型求解"></a>2.3 模型求解</h4><p><br />因此，原问题可以转化为对偶问题</p>

$$
\begin{aligned}
L(w,b,\lambda) = \frac{w^Tw}{2} - \sum_i^n \lambda_i(y_i(w^Tx_i + b) - 1) \quad(3)\\
\min_{w,b}\max_{\lambda}L(w,b,\lambda) 
\rightarrow \max_{\lambda}\min_{w,b}L(w,b,\lambda)
\end{aligned}
$$


<p>求解：<br /></p>
<ol>
<li>对 w，b 求偏导数并令其等于0
$$
\begin{aligned}
\frac{dL}{dw} = w - \sum_i^n\lambda_iy_ix_i = 0 \quad(4)\\
\frac{dL}{db} = -\sum_i^n \lambda_iy_i = 0 
\quad(5)
\end{aligned}
$$
</li>
</ol>
<br />

<ol start="2">
<li>将（4),(5）带入到(3)中，可得：</li>
</ol>

$$
\begin{aligned}
G(\lambda) &= \frac{\sum_i^n\lambda_iy_ix_i^T\sum_i^n\lambda_iy_ix_i}{2} - \sum_i^n \lambda_i(y_i(\sum_j^n\lambda_jy_jx_j^Tx_i + b) - 1)   \\
&= \frac{\sum_i^n\lambda_iy_ix_i^T\sum_i^n\lambda_iy_ix_i}{2} - \sum_i^n \lambda_i(y_i(\sum_j^n\lambda_jy_jx_j^Tx_i)) +\sum_i^n\lambda_i \\
&= \sum_i^n\lambda_i - \frac{\sum_i^n\sum_j^n\lambda_jy_ix_jx_i^T\lambda_iy_i}{2} \\
\end{aligned}\tag{6}
$$


<p><br />此时优化问题为:</p>

$$\begin{aligned}
&\max_{\lambda} G(\lambda) \\
s.t.\quad & \sum_i^n \lambda_iy_i = 0 \\
 &\lambda_i >= 0
\end{aligned}  \tag{7}
$$


<ol>
<li>对G函数求极大值，即可得到解 $\lambda^{\star}$， 带入到 (4),(5) 可以求解出 $w^{\star} = \sum_i^n \lambda^{\star}_iy_ix_i$。 </li>
</ol>
<ol start="2">
<li>求解b, 易知存在 $\lambda_j \neq 0$（可以使用反证法证明，若全部$\lambda$均为0，则 w为0，而w=0不是原始优化问题的解）。此时，有$y_i(w^{\star} \cdot x_i + b ) - 1 = 0$,可得 $b^{\star} = y_i^2 - w^{\star} \cdot x_i$ 。</li>
</ol>
<p><a name="swkyj"></a></p>
<h4 id="2-4-支撑向量"><a href="#2-4-支撑向量" class="headerlink" title="2.4 支撑向量"></a>2.4 支撑向量</h4><p><br />由2.3 第3、4步可知，如果只保留 $\lambda \neq 0, \quad y(w^Tx + b) - 1 = 0$ 对应的x,y，求得的结果w和b不变。 因此把这些向量称之为支撑向量，即 <code>support vector</code>。</p>
<p><a name="L1qaJ"></a></p>
<h2 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h2><ol>
<li>统计学习方法. 李航. chapter 7</li>
<li>机器学习. 周志华</li>
</ol>
</div><div class="article-licensing box"><div class="licensing-title"><p>Hard-SVM</p><p><a href="https://codeflysafe.github.io/2020/09/27/SVM(1)_ Hard-SVM/">https://codeflysafe.github.io/2020/09/27/SVM(1)_ Hard-SVM/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>sjhuang</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2020-09-27</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2022-02-18</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/machine-learning/">machine learning</a><a class="link-muted mr-2" rel="tag" href="/tags/classification/">classification</a><a class="link-muted mr-2" rel="tag" href="/tags/SVM/">SVM</a></div><!--!--></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" href="/" target="_blank" rel="noopener" data-type="afdian"><span class="icon is-small"><i class="fas fa-charging-station"></i></span><span>爱发电</span></a><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="/" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/10/10/SVM(2)_%20Soft-SVM/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Soft-SVM</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/09/23/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E4%B8%8EBP%E7%AE%97%E6%B3%95/"><span class="level-item">多层感知机与BP算法</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="comment-container"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js"></script><script>var gitalk = new Gitalk({
            id: "a2dbc9c2daaa0801878c6dadd124879e",
            repo: "gitalk",
            owner: "codeflysafe",
            clientID: "48d1eb3658ef4923896f",
            clientSecret: "d619d46a6c36396cab7dc0190ad1630bd3982b34",
            admin: ["codeflysafe"],
            createIssueManually: false,
            distractionFreeMode: false,
            perPage: 10,
            pagerDirection: "last",
            
            
            enableHotKey: true,
            
        })
        gitalk.render('comment-container')</script></div></div></div><!--!--><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="魔法沉思录" height="28"></a><p class="is-size-7"><span>&copy; 2022 sjhuang</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>